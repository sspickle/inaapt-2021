{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffa44dc",
   "metadata": {},
   "source": [
    "# Bayesian Inference\n",
    "\n",
    "Examples of Bayesian Inference for join ILAAPT/INAAPT Spring Meeting April 24, 2021\n",
    "\n",
    "The `empiricaldist` package is from [Allen B Downey](https://github.com/AllenDowney)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some packages we'll need later\n",
    "\n",
    "import pymc3 as pm  # Markov Chain Monte Carlo\n",
    "import arviz as az  # visualization\n",
    "import numpy as np  # numpy\n",
    "import matplotlib.pyplot as plt # make pretty graphs\n",
    "import pandas as pd\n",
    "from empiricaldist import Pmf   # Learn about Bayesian inference. A \"Pmf\" is a \"probability mass function\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a basket of fruit!\n",
    "A=Pmf({'orange':2, 'apple':5, 'plum':7});\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert counts to probabilities\n",
    "A.normalize()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df33aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's easy to retrieve the probability of an outcome\n",
    "A['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can multiply probabilties by a simple list of numbers and it \"does the right thing\" for Bayesian work.\n",
    "A*[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=Pmf({'orange':4, 'apple':1, 'plum':12}); \n",
    "B.normalize()\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c27fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a nice way to display both baskets together\n",
    "pd.DataFrame({'A':A, 'B':B})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = Pmf(1,['A','B'])\n",
    "hypotheses.normalize()\n",
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'orange'\n",
    "A[data],B[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = hypotheses*[A[data],B[data]]\n",
    "hypotheses.normalize()\n",
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'plum'\n",
    "hypotheses = hypotheses*[A[data],B[data]]\n",
    "hypotheses.normalize()\n",
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'plum'\n",
    "hypotheses = hypotheses*[A[data],B[data]]\n",
    "hypotheses.normalize()\n",
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in B.choice(10):\n",
    "    hypotheses = hypotheses*[A[data],B[data]]\n",
    "\n",
    "hypotheses.normalize()\n",
    "hypotheses    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133b83c",
   "metadata": {},
   "source": [
    "# Machinery to handle continuous distributions\n",
    "\n",
    "Many times we don't have discrete distributions, but rather continuous random variables. We can fake this with PMFs, but to really get it right, we need something a bit more sophisticated. Here is a simple example of a linear fit using randomly generated data to illustrate the pymc3 machinery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generative model, simple normal distribution\n",
    "\n",
    "x1 = np.random.normal(size=20)*.5 + 2\n",
    "\n",
    "with pm.Model() as normal_model:\n",
    "    mu = pm.Normal('mu',mu=0,sigma=5)  # prior distribution for mu\n",
    "    sig = pm.HalfNormal('sig',sigma=2) # prior distribution for sigma\n",
    "    \n",
    "    x_obs = pm.Normal(\"x_obs\", mu=mu, sigma=sig, observed=x1) # relationship to observed data\n",
    "    trace = pm.sample(1000, return_inferencedata=True)\n",
    "    \n",
    "print(az.summary(trace, kind=\"stats\"))\n",
    "_=az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be414a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.normal(size=100)*.3+4.1\n",
    "x2 = np.random.normal(size=70)*.2+4.3\n",
    "\n",
    "_=plt.hist(x1)\n",
    "_=plt.hist(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71de602",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as diff_model:\n",
    "    mu1 = pm.Uniform('mu1',0,10)  # prior distribution for mu1\n",
    "    mu2 = pm.Uniform('mu2',0,10)  # prior for mu2\n",
    "    sig1 = pm.HalfNormal('sig1',sigma=2) # prior distribution for sigma1\n",
    "    sig2 = pm.HalfNormal('sig2',sigma=2) # prior distribution for sigma2\n",
    "    \n",
    "    x1_obs = pm.Normal(\"x1_obs\", mu=mu1, sigma=sig1, observed=x1) # relationship to observed data\n",
    "    x2_obs = pm.Normal(\"x2_obs\", mu=mu2, sigma=sig2, observed=x2) # relationship to observed data\n",
    "\n",
    "    diff = pm.Deterministic(\"x_diff\", mu2 - mu1)\n",
    "\n",
    "    trace = pm.sample(1000, return_inferencedata=True)\n",
    "    \n",
    "print(az.summary(trace, kind=\"stats\"))\n",
    "_=az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,20)\n",
    "m_gen = 2.5\n",
    "b_gen = 1.3\n",
    "s_gen = 0.3\n",
    "\n",
    "y_th = m_gen*x + b_gen\n",
    "y_noise = y_th + s_gen*np.random.normal(size=(len(x))) # y = m*x + b + noise\n",
    "\n",
    "plt.plot(x,y_noise,'b.',label='fake data (w/noise)')\n",
    "plt.plot(x,y_th,'r-',label='theory: no noise')\n",
    "plt.title('generated test data')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    m = pm.Uniform('m',0,5)  # prior distribution for m\n",
    "    b = pm.Uniform('b',0,5)  # prior distribution for b\n",
    "    s = pm.Uniform('s',0,2)  # prior distribution for s\n",
    "    \n",
    "    y_obs = pm.Normal('y_obs',mu=m*x+b, sigma=s, observed=y_noise) # relate to measured values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e35f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(1000, return_inferencedata=True)\n",
    "    \n",
    "print(az.summary(trace, kind=\"stats\"))\n",
    "_=az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2912809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's useful to inspect the resulting trace object\n",
    "\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_post = trace.posterior.m.values.mean()*x + trace.posterior.b.values.mean()\n",
    "plt.plot(x,y_noise,'b.',label='observed y values')\n",
    "plt.plot(x,y_post,'r-',label='posterior line from mean parameters')\n",
    "plt.title('fit from generated test data')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_m = trace.posterior.m.values.flatten()\n",
    "all_b = trace.posterior.b.values.flatten()\n",
    "\n",
    "N = 1000\n",
    "\n",
    "for i in range(N):\n",
    "    y_post = all_m[i]*x + all_b[i]\n",
    "    plt.plot(x,y_post,'r-',alpha=0.1)\n",
    "    \n",
    "plt.plot(x,y_noise,'b.',label='observed y values')\n",
    "plt.title('fit from generated test data')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ae6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "print(\"pymc3 is version {:s}\".format(pm.__version__))\n",
    "print(\"arviz is version {:s}\".format(az.__version__))\n",
    "print(\"numpy is version {:s}\".format(np.__version__))\n",
    "print(\"pandas is version {:s}\".format(pd.__version__))\n",
    "print(\"matplotlib is version {:s}\".format(matplotlib.__version__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
